{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import zipfile\n",
    "import xarray as xr \n",
    "import rioxarray as rio \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import schedule\n",
    "import requests\n",
    "from pcse.util import reference_ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are downloaded from AgERA5 provided by CDS (https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-agrometeorological-indicators?tab=overview), through the cdsapi package. This has the advantage of magaging the caching of already passed requests, thus to speed up the downloading process.\n",
    "\n",
    "Frequency update : daily with a 7-day lag (https://confluence.ecmwf.int/display/CUSF/AgERA-5+frequency+update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_point_to_area(points, selected_point):\n",
    "    print(\"===== convert_point_to_area =====\")\n",
    "    #fonctionne seulement dans le nord ?\n",
    "    area = points\n",
    "    # area[selected_point] = [np.round(points[selected_point][0]*4,0)/4,\n",
    "    #                         np.round(points[selected_point][1]*4,0)/4-0.25,\n",
    "    #                         np.round(points[selected_point][0]*4,0)/4-0.25,\n",
    "    #                         np.round(points[selected_point][1]*4,0)/4,]\n",
    "    area[selected_point] = [np.round(np.round(points[selected_point][0]*10,0)/10+0.1,2),\n",
    "                            np.round(np.round(points[selected_point][1]*10,0)/10-0.1,2),\n",
    "                            np.round(np.round(points[selected_point][0]*10,0)/10-0.1,2),\n",
    "                            np.round(np.round(points[selected_point][1]*10,0)/10+0.1,2),]\n",
    "    return area, selected_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_AgERA5_year(selected_area, variables, query_year):\n",
    "\n",
    "    # the objective is to download the whole year\n",
    "\n",
    "    print(\"===== download_AgERA5_year =====\")\n",
    "\n",
    "    # try:\n",
    "    \n",
    "\n",
    "    c = cdsapi.Client()\n",
    "\n",
    "    if not os.path.exists('../data/0_downloads/'):\n",
    "        os.makedirs('../data/0_downloads/')\n",
    "\n",
    "    for variable in variables :\n",
    "        \n",
    "        print(\"\\nDownloading values for variable\",variable,\"for year\", query_year)\n",
    "\n",
    "        zip_path = '../data/0_downloads/AgERA5_'+selected_area+'_'+variable[0]+'_'+variable[1]+\"_\"+str(query_year)+'.zip'\n",
    "\n",
    "        data_points = {}\n",
    "\n",
    "        request = {\n",
    "                'format': 'zip',\n",
    "                'day': [\n",
    "                    '01', '02', '03',\n",
    "                    '04', '05', '06',\n",
    "                    '07', '08', '09',\n",
    "                    '10', '11', '12',\n",
    "                    '13', '14', '15',\n",
    "                    '16', '17', '18',\n",
    "                    '19', '20', '21',\n",
    "                    '22', '23', '24',\n",
    "                    '25', '26', '27',\n",
    "                    '28', '29', '30',\n",
    "                    '31',\n",
    "                ],\n",
    "                'month': [\n",
    "                    '01', '02', '03',\n",
    "                    '04', '05', '06',\n",
    "                    '07', '08', '09',\n",
    "                    '10', '11', '12',\n",
    "                ],\n",
    "                'year': [str(query_year)],\n",
    "                'variable': variable[0],\n",
    "                'statistic': variable[1],\n",
    "                'area': area[selected_area],\n",
    "            }\n",
    "\n",
    "        # la requête doit être adaptée pour cette variable\n",
    "        if variable[0] == \"solar_radiation_flux\" :\n",
    "            del request[\"statistic\"]\n",
    "\n",
    "        c.retrieve(\n",
    "            'sis-agrometeorological-indicators',\n",
    "            request,\n",
    "            zip_path)\n",
    "\n",
    "        print(\"Download OK\")\n",
    "\n",
    "    # except :\n",
    "    #     print(\"/!\\ Download NOT OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_agERA5_year(selected_area, variables, query_year):\n",
    "\n",
    "    print(\"===== extract_agERA5_year =====\")\n",
    "\n",
    "    # try:\n",
    "    # query_year = query_date.year\n",
    "    # query_month = query_date.strftime('%m')\n",
    "\n",
    "    for variable in tqdm(variables) :\n",
    "\n",
    "        zip_path = '../data/0_downloads/AgERA5_'+selected_area+'_'+variable[0]+'_'+variable[1]+\"_\"+str(query_year)+'.zip'\n",
    "        extraction_path = '../data/1_extraction/AgERA5_'+selected_area+'_'+variable[0]+'_'+variable[1]+\"_\"+str(query_year)+'/'\n",
    "\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extraction_path)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"Extraction OK\")\n",
    "\n",
    "    # except :\n",
    "    #     print(\"/!\\ Extraction NOT OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_and_save_AgERA_year(selected_area, variables, query_year):\n",
    "\n",
    "    print(\"===== format_and_save_AgERA_year =====\")\n",
    "\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    print(\"- Reading netCDF files to Pandas dataframe...\")\n",
    "\n",
    "    df_weather_collection = {}\n",
    "    df_weather = pd.DataFrame()\n",
    "\n",
    "    for variable in variables :\n",
    "        \n",
    "        df_weather_collection[variable[0]] = pd.DataFrame()\n",
    "\n",
    "        extraction_path = '../data/1_extraction/AgERA5_'+selected_area+'_'+variable[0]+'_'+variable[1]+\"_\"+str(query_year)+'/'\n",
    "        nc_files = os.listdir(extraction_path)\n",
    "        conversion_path = '../data/2_conversion/AgERA5_'+selected_area+'_'+variable[0]+'_'+variable[1]+\"_\"+str(query_year)+'/'\n",
    "        if not os.path.exists(conversion_path):\n",
    "            os.makedirs(conversion_path)\n",
    "        for nc_file in tqdm(nc_files) :\n",
    "            # d'après https://help.marine.copernicus.eu/en/articles/5029956-how-to-convert-netcdf-to-geotiff\n",
    "            nc_file_content = xr.open_dataset(os.path.join(extraction_path, nc_file))\n",
    "            xarray_variable_name = list(nc_file_content.keys())[0]\n",
    "            bT = nc_file_content[xarray_variable_name]\n",
    "\n",
    "            value = nc_file_content.sel(\n",
    "                lat=points[selected_point][0], \n",
    "                lon=points[selected_point][1],\n",
    "                method=\"nearest\")[xarray_variable_name].values[0]\n",
    "\n",
    "            df_weather_collection[variable[0]] = df_weather_collection[variable[0]].append(pd.DataFrame({variable:value, \"Jour\":pd.Timestamp(nc_file_content[\"time\"].values[0]).date()}, index=[0]))\n",
    "\n",
    "        if variable == variables[0]:\n",
    "            df_weather = df_weather_collection[variable[0]]\n",
    "        else :\n",
    "            df_weather = df_weather.merge(df_weather_collection[variable[0]], left_on = \"Jour\", right_on=\"Jour\")\n",
    "\n",
    "    df_weather = df_weather.rename(columns=variables_corresp)\n",
    "\n",
    "    print(\"- Converting units...\")\n",
    "\n",
    "    # calculating variables\n",
    "    df_weather[[\"TMin\", \"TMax\", \"TMoy\"]] = df_weather[[\"TMin\", \"TMax\", \"TMoy\"]] - 273.15\n",
    "    df_weather[\"Rg\"] = df_weather[\"Rg\"]/1E6\n",
    "    # calcul du RH depuis actual vapour pressure : https://www.weather.gov/media/epz/wxcalc/vaporPressure.pdf\n",
    "    df_weather[\"es\"] = 6.11 * 10 ** ((7.5 * df_weather[\"TMoy\"])/(237.3 + df_weather[\"TMoy\"]))\n",
    "    df_weather[\"HMoy\"] = (df_weather[\"Vap\"]/df_weather[\"es\"]) * 100\n",
    "\n",
    "    print(\"- Retrieving elevation at request coordinates...\")\n",
    "\n",
    "    response = requests.get(\"https://api.open-elevation.com/api/v1/lookup?locations=\"+str(points[selected_point][0])+\",\"+str(points[selected_point][1]))\n",
    "    df_weather[\"ELEV\"] = response.json()['results'][0][\"elevation\"]\n",
    "\n",
    "    print(\"- Computing ET0-PM...\")\n",
    "\n",
    "    ANGSTA = 0.29\n",
    "    ANGSTB = 0.49\n",
    "    df_weather[\"ET0_PM\"] = df_weather.apply(lambda x: reference_ET(x[\"Jour\"], points[selected_point][0], x[\"ELEV\"], x[\"TMin\"], x[\"TMax\"], x[\"Rg\"]*1E6, x[\"Vap\"], x[\"Vt\"], ANGSTA, ANGSTB, ETMODEL=\"PM\")[2], axis=1)\n",
    "\n",
    "    print(\"- Saving...\")\n",
    "\n",
    "    df_weather.to_csv(\"../data/3_output/AgERA5_point_\"+selected_point+\"_\"+str(points[selected_point][0])+\"_\"+str(points[selected_point][1])+\"_weather_\"+str(query_year)+\".csv\")\n",
    "\n",
    "    print(\"- Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_AgERA5_intermediate_files(dump):\n",
    "    print(\"===== delete_AgERA5_intermediate_files =====\")\n",
    "    try:\n",
    "        if dump == True:\n",
    "            import shutil\n",
    "            shutil.rmtree( '../data/0_downloads/' )\n",
    "            shutil.rmtree( '../data/1_extraction/' )\n",
    "            shutil.rmtree( '../data/2_conversion/' )\n",
    "        print(\"Deletion of intermediate files OK\")\n",
    "    except:\n",
    "        print(\"/!\\ Deletion of intermediate files NOT OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "points = {'bobo_dioulasso': [11.18, -4.28]} #lat, lon\n",
    "selected_point = \"bobo_dioulasso\"\n",
    "variables = [\n",
    "    (\"2m_temperature\",\"24_hour_minimum\"),\n",
    "    (\"2m_temperature\",\"24_hour_maximum\"),\n",
    "    (\"solar_radiation_flux\", \"daily\"),\n",
    "    (\"vapour_pressure\", \"24_hour_mean\"),\n",
    "    (\"10m_wind_speed\", \"24_hour_mean\"),\n",
    "    (\"2m_temperature\",\"24_hour_mean\"),\n",
    "]\n",
    "\n",
    "# correspondance entre noms de variables dans AgERA5 et le nom des variables souhaité dans SARRA\n",
    "variables_corresp = {\n",
    "    (\"2m_temperature\",\"24_hour_minimum\"): \"TMin\",\n",
    "    (\"2m_temperature\",\"24_hour_maximum\"): \"TMax\",\n",
    "    (\"solar_radiation_flux\", \"daily\"): \"Rg\",\n",
    "    (\"vapour_pressure\", \"24_hour_mean\"): \"Vap\",\n",
    "    (\"10m_wind_speed\", \"24_hour_mean\"): \"Vt\",\n",
    "    (\"2m_temperature\",\"24_hour_mean\"): \"TMoy\",\n",
    "}\n",
    "query_year = 2020\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== convert_point_to_area =====\n",
      "===== download_AgERA5_year =====\n",
      "\n",
      "Downloading values for variable ('2m_temperature', '24_hour_minimum') for year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download OK\n",
      "\n",
      "Downloading values for variable ('2m_temperature', '24_hour_maximum') for year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download OK\n",
      "\n",
      "Downloading values for variable ('solar_radiation_flux', 'daily') for year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download OK\n",
      "\n",
      "Downloading values for variable ('vapour_pressure', '24_hour_mean') for year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download OK\n",
      "\n",
      "Downloading values for variable ('10m_wind_speed', '24_hour_mean') for year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download OK\n",
      "\n",
      "Downloading values for variable ('2m_temperature', '24_hour_mean') for year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download OK\n",
      "===== extract_agERA5_month =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:06<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction OK\n",
      "===== format_and_save_AgERA_year =====\n",
      "- Reading netCDF files to Pandas dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:04<00:00, 75.18it/s]\n",
      "100%|██████████| 366/366 [00:05<00:00, 68.24it/s]\n",
      "100%|██████████| 366/366 [00:05<00:00, 65.55it/s]\n",
      "100%|██████████| 366/366 [00:05<00:00, 63.66it/s]\n",
      "100%|██████████| 366/366 [00:05<00:00, 70.46it/s]\n",
      "100%|██████████| 366/366 [00:05<00:00, 71.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Converting units...\n",
      "- Retrieving elevation at request coordinates...\n",
      "- Computing ET0-PM...\n",
      "- Saving...\n",
      "- Done !\n",
      "===== delete_AgERA5_intermediate_files =====\n",
      "Deletion of intermediate files OK\n"
     ]
    }
   ],
   "source": [
    "area, selected_area = convert_point_to_area(points, selected_point)\n",
    "download_AgERA5_year(selected_area, variables, query_year)\n",
    "extract_agERA5_year(selected_area, variables, query_year)\n",
    "format_and_save_AgERA_year(selected_area, variables, query_year)\n",
    "delete_AgERA5_intermediate_files(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv_sarra_data_download')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a619a3e580409126cc44b05b414d75e5414ec3ffa31020c3aba01dc643503166"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
